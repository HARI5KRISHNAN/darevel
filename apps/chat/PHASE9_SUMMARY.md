# Phase 9: Monitoring & Alerting - Implementation Summary

## Overview

Phase 9 transforms Whooper into a **self-monitoring platform** with real-time metrics collection, visual dashboards, and automated email alerting.

## What Was Implemented

### 1. Prometheus Metrics Integration

**Backend Metrics Utility** ([backend/src/utils/metrics.ts](backend/src/utils/metrics.ts))
- Created Prometheus client registry
- Configured default Node.js metrics (CPU, memory, GC, event loop)
- Defined 30+ custom application metrics across 7 categories

**Metrics Endpoint** ([backend/src/server.ts](backend/src/server.ts))
- Added `GET /metrics` endpoint for Prometheus scraping
- Added `GET /api/health` endpoint for health checks
- Implemented request tracking middleware
- Updates pod metrics before each scrape

**Custom Metrics Categories:**
1. **Pod Metrics** - Total, running, pending, failed pods
2. **HTTP Metrics** - Request count, duration histograms by route/status
3. **AI Metrics** - Summary requests, subject suggestions, API latency
4. **Email Metrics** - Sent/failed emails, API latency
5. **Alert Metrics** - Triggered/resolved by severity and type
6. **Incident Metrics** - Created incidents, MTTR histograms
7. **WebSocket Metrics** - Active connections, messages sent/received

### 2. Kubernetes ServiceMonitor

**ServiceMonitor Configuration** ([k8s/monitoring/servicemonitor.yaml](k8s/monitoring/servicemonitor.yaml))
- Tells Prometheus to scrape Whooper backend every 15 seconds
- Targets `/metrics` endpoint on port 5001
- Uses label selectors to find Whooper backend pods
- Compatible with Prometheus Operator

### 3. Prometheus Alert Rules

**Alert Rules** ([k8s/monitoring/prometheus-rules.yaml](k8s/monitoring/prometheus-rules.yaml))

Defined 15+ alert rules across 5 categories:

**Application Alerts (5):**
- `WhooperBackendDown` - Service down for 2+ minutes
- `WhooperHighErrorRate` - >5% HTTP 5xx errors
- `WhooperSlowRequests` - p95 latency >5 seconds
- `WhooperHighMemoryUsage` - >90% memory usage
- `WhooperHighCPUUsage` - >80% CPU for 5 minutes

**Kubernetes Alerts (5):**
- `PodDown` - Pod in Failed state
- `PodCrashLooping` - Frequent pod restarts
- `PodPending` - Stuck in Pending >10 minutes
- `HighPodMemory` - >90% memory limit
- `HighPodCPU` - >90% CPU for 10 minutes

**AI Service Alerts (2):**
- `GeminiAPIErrors` - High Gemini API error rate
- `SlowAIResponses` - p95 latency >10 seconds

**Email Service Alerts (1):**
- `EmailServiceUnreachable` - >50% email failures

**Incident Alerts (2):**
- `HighIncidentRate` - >5 incidents per 15 minutes
- `HighMTTR` - p95 MTTR >1 hour for critical incidents

**Alert Features:**
- Severity levels: critical, warning, info
- Detailed annotations with summary, description, action
- Namespace, pod, container context
- Generator URLs for Prometheus deep-linking

### 4. AlertManager Configuration

**AlertManager Config** ([k8s/monitoring/alertmanager-config.yaml](k8s/monitoring/alertmanager-config.yaml))

**Routing Configuration:**
- **Critical alerts** â†’ 10s group wait, 1h repeat interval
- **Warning alerts** â†’ 1m group wait, 4h repeat interval
- **Pod alerts** â†’ 30s group wait, 2h repeat interval

**Features:**
- Webhook integration with Whooper backend
- Alert grouping by alertname, cluster, namespace
- Inhibition rules (suppress warnings when critical fires)
- Custom alert templates for formatting
- Deduplication and rate limiting

**Alert Templates:**
- Created custom template for better email formatting
- Includes all alert metadata
- Formatted for readability

### 5. Alert Webhook Handler

**Alerts Controller** ([backend/src/controllers/alerts.controller.ts](backend/src/controllers/alerts.controller.ts))

**Webhook Endpoint:** `POST /api/alerts/webhook`

**Features:**
- Receives AlertManager webhook payloads
- Processes multiple alerts in single request
- Generates beautiful HTML email notifications
- Plain text fallback for email clients
- Updates metrics counters
- Severity-based emoji indicators
- Timeline with duration calculations
- Action recommendations in emails

**Email Template:**
- Professional HTML email design
- Color-coded by severity (critical=red, warning=yellow)
- Responsive layout
- All alert metadata included
- Links to Prometheus for investigation
- Branded footer

**Supported Alert Payload:**
- Prometheus AlertManager v2 webhook format
- Firing and resolved status
- Multiple alerts per webhook
- Full label and annotation support

**Route Registration** ([backend/src/routes/alerts.routes.ts](backend/src/routes/alerts.routes.ts))
- Added webhook route to existing alerts router
- Integrated with email service
- Metrics tracking for alerts

### 6. Grafana Dashboard

**Dashboard JSON** ([k8s/monitoring/grafana-dashboard.json](k8s/monitoring/grafana-dashboard.json))

**11 Dashboard Panels:**

**Row 1 - Status Overview (4 stat panels):**
1. Total Pods Monitored
2. Running Pods (green)
3. Pending Pods (yellow/orange)
4. Failed Pods (red)

**Row 2 - Trends (2 time series):**
5. Pod Status Over Time (line chart)
6. HTTP Requests by Status Code (line chart)

**Row 3 - Resources (2 time series):**
7. Pod Memory Usage (with mean/max stats)
8. Pod CPU Usage (with mean/max stats)

**Row 4 - Performance (2 time series):**
9. HTTP Request Latency p50/p95 (line chart)
10. Email Send Rate (line chart)

**Row 5 - Alerts (1 bar chart):**
11. Alert Trigger Rate by Severity (stacked bars)

**Dashboard Features:**
- Auto-refresh every 10 seconds
- Default time range: Last 1 hour
- Dark theme
- Prometheus datasource
- Tagged for easy discovery
- UID for consistent importing

### 7. Comprehensive Documentation

**Monitoring Guide** ([PHASE9_MONITORING.md](PHASE9_MONITORING.md))

**Sections:**
1. **Overview** - What gets monitored, alert conditions
2. **Architecture** - Flow diagram from pods â†’ Prometheus â†’ AlertManager â†’ Email
3. **Metrics Collected** - All 30+ metrics documented
4. **Setup Guide** - Step-by-step installation
5. **Alert Configuration** - How to customize alerts
6. **Grafana Dashboard** - Panel descriptions and PromQL examples
7. **Testing** - 7 test scenarios with expected results
8. **Troubleshooting** - 6 common issues with solutions

## Files Created/Modified

### New Files
1. `backend/src/utils/metrics.ts` - Prometheus metrics definitions
2. `backend/src/controllers/alerts.controller.ts` - Webhook handler
3. `k8s/monitoring/servicemonitor.yaml` - ServiceMonitor config
4. `k8s/monitoring/prometheus-rules.yaml` - Alert rules
5. `k8s/monitoring/alertmanager-config.yaml` - AlertManager config
6. `k8s/monitoring/grafana-dashboard.json` - Grafana dashboard
7. `PHASE9_MONITORING.md` - Comprehensive documentation
8. `PHASE9_SUMMARY.md` - This file

### Modified Files
1. `backend/package.json` - Added prom-client dependency
2. `backend/src/server.ts` - Added metrics endpoint and middleware
3. `backend/src/routes/alerts.routes.ts` - Added webhook route

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Scrape every 15s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Whooper    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Prometheus  â”‚   â”‚
â”‚  â”‚   Backend    â”‚                       â”‚              â”‚   â”‚
â”‚  â”‚              â”‚                       â”‚  - Collect   â”‚   â”‚
â”‚  â”‚  /metrics    â”‚                       â”‚  - Store     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚  - Query     â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                â”‚            â”‚
â”‚                                    Evaluate rules every 30sâ”‚
â”‚                                                â–¼            â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚ AlertManager â”‚   â”‚
â”‚                                         â”‚              â”‚   â”‚
â”‚                                         â”‚  - Route     â”‚   â”‚
â”‚                                         â”‚  - Group     â”‚   â”‚
â”‚                                         â”‚  - Dedupe    â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                â”‚            â”‚
â”‚                                   Webhook to backend       â”‚
â”‚                                                â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       Send email     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Whooper    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Email     â”‚   â”‚
â”‚  â”‚   Backend    â”‚                       â”‚  Assistant   â”‚   â”‚
â”‚  â”‚ /api/alerts/ â”‚                       â”‚              â”‚   â”‚
â”‚  â”‚   webhook    â”‚                       â”‚              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                                        ğŸ“§ Email to Admin
```

## Metrics Collected

### Application Metrics (30+)

**Pod Metrics:**
```
whooper_pods_total
whooper_pods_running
whooper_pods_pending
whooper_pods_failed
```

**HTTP Metrics:**
```
whooper_http_requests_total{method,route,status}
whooper_http_request_duration_seconds{method,route}
```

**AI Metrics:**
```
whooper_ai_summary_requests_total{status}
whooper_ai_subject_suggestion_requests_total{status,type}
whooper_ai_api_latency_seconds{operation}
```

**Email Metrics:**
```
whooper_emails_sent_total{type,status}
whooper_email_api_latency_seconds
```

**Alert Metrics:**
```
whooper_alerts_triggered_total{severity,type}
whooper_alerts_resolved_total{type}
```

**Incident Metrics:**
```
whooper_incidents_created_total{severity,namespace}
whooper_incident_mttr_seconds{severity}
```

**WebSocket Metrics:**
```
whooper_websocket_connections
whooper_websocket_messages_received_total
whooper_websocket_messages_sent_total{event}
```

### Default Node.js Metrics (10+)

```
whooper_process_cpu_*
whooper_process_resident_memory_bytes
whooper_nodejs_heap_size_*
whooper_nodejs_eventloop_lag_seconds
whooper_nodejs_gc_duration_seconds
```

## Alert Email Example

When an alert fires, admin receives an HTML email:

```
Subject: ğŸš¨ [ALERT] PodDown

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       ğŸš¨ ALERT TRIGGERED                â”‚  (Red background)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PodDown                                    CRITICAL

Summary
Pod Failure Detected

Description
Pod my-app-xyz in namespace production has failed.

Details
Namespace:    production
Pod:          my-app-xyz
Container:    app
Started:      2025-02-10 14:23:45

âš¡ Action Required
Check pod logs: kubectl logs -n production my-app-xyz

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
This alert was sent by Whooper Kubernetes Monitoring
View in Prometheus â†’
```

## Setup Quick Reference

```bash
# 1. Install Prometheus stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace

# 2. Deploy monitoring configs
kubectl apply -f k8s/monitoring/

# 3. Configure AlertManager
kubectl patch alertmanager prometheus-kube-prometheus-alertmanager \
  -n monitoring --type merge \
  -p '{"spec":{"configSecret":"alertmanager-whooper"}}'

# 4. Import Grafana dashboard
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Upload k8s/monitoring/grafana-dashboard.json

# 5. Configure email recipient
kubectl create secret generic whooper-backend-secrets \
  --from-literal=ALERT_EMAIL="admin@example.com" \
  --namespace=whooper --dry-run=client -o yaml | kubectl apply -f -

# 6. Restart backend
kubectl rollout restart deployment/whooper-backend -n whooper
```

## Testing

### Verify Metrics Endpoint
```bash
kubectl port-forward -n whooper svc/whooper-backend 5001:5001
curl http://localhost:5001/metrics
```

### Trigger Test Alert
```bash
# Create failing pod
kubectl run test-fail --image=busybox --command -- /bin/sh -c "exit 1"

# Wait 1-2 minutes, check alerts
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# Open http://localhost:9090/alerts
```

### Access Grafana
```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Get password:
kubectl get secret -n monitoring prometheus-grafana \
  -o jsonpath="{.data.admin-password}" | base64 -d
# Open http://localhost:3000
```

## Key Features

### Metrics Collection
- **30+ custom metrics** across application, AI, email, alerts
- **10+ default Node.js metrics** for runtime monitoring
- **15-second scrape interval** for near real-time data
- **Automatic pod discovery** via ServiceMonitor

### Alerting
- **15+ predefined alert rules** covering common failure scenarios
- **Severity-based routing** (critical, warning, info)
- **Alert grouping** to reduce noise
- **Inhibition rules** to suppress redundant alerts
- **Email notifications** with beautiful HTML templates

### Visualization
- **11-panel Grafana dashboard** with status, trends, resources
- **Auto-refresh** every 10 seconds
- **Color-coded panels** (green/yellow/red thresholds)
- **PromQL queries** for advanced analysis

### Integration
- **Email service integration** via existing email assistant
- **Webhook-based alerting** for flexibility
- **Metrics tracking** for alerts and incidents
- **Prometheus Operator** for easy management

## Benefits

1. **Proactive Monitoring** - Know about issues before users report them
2. **Automatic Alerting** - Email notifications when problems occur
3. **Visual Dashboards** - Real-time visibility into system health
4. **Performance Tracking** - Monitor latency, errors, throughput
5. **Capacity Planning** - Track resource usage over time
6. **Incident Tracking** - MTTR and incident metrics
7. **Production Ready** - Industry-standard monitoring stack

## Next Steps

After Phase 9, you can proceed to:

### Option 1: Phase 10a - Auto-Healing
- Automatic pod restart on failure
- AI-generated incident reports sent via email
- Root cause analysis
- Self-healing actions

### Option 2: Phase 10b - Advanced Analytics
- Centralized analytics dashboard
- Trend analysis and predictions
- Usage reports and summaries
- Capacity planning insights

### Monitoring Enhancements
- Slack/PagerDuty integration for alerts
- Distributed tracing with Jaeger
- Log aggregation with Loki
- SLA tracking and reporting
- Custom dashboards per team

## Troubleshooting Reference

| Issue | Solution |
|-------|----------|
| Metrics endpoint 404 | Rebuild backend, check logs |
| ServiceMonitor not found | Apply `servicemonitor.yaml` |
| Alerts not firing | Check PrometheusRule, verify expressions |
| No email notifications | Verify webhook URL, check backend logs |
| Dashboard shows no data | Check Prometheus datasource, verify scraping |

For detailed troubleshooting, see [PHASE9_MONITORING.md](PHASE9_MONITORING.md).

## Summary

Phase 9 successfully implemented a complete monitoring and alerting infrastructure:

- **Metrics**: 30+ custom application metrics + Node.js defaults
- **Scraping**: ServiceMonitor for automatic discovery
- **Alerting**: 15+ alert rules with email notifications
- **Visualization**: 11-panel Grafana dashboard
- **Integration**: Webhook â†’ Email workflow
- **Documentation**: Comprehensive setup and troubleshooting guide

Whooper is now a **self-monitoring platform** that provides real-time visibility into pod health, performance, and alerts administrators when issues occur.

**Total Implementation:**
- 8 new files created
- 3 files modified
- 1000+ lines of monitoring configuration
- Production-ready monitoring stack
